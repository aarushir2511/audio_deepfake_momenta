{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core packages\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths and configuration\n",
    "AUDIO_DIR = \"LA/ASVspoof2019_LA_train/flac\"\n",
    "PROTO_FILE = \"LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "\n",
    "CLASSES = 2\n",
    "SRATE = 16000\n",
    "AUDIO_LEN = 5  # seconds\n",
    "MEL_BANDS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create label dictionary from protocol file\n",
    "file_labels = {}\n",
    "\n",
    "with open(PROTO_FILE, 'r') as proto:\n",
    "    for line in proto:\n",
    "        parts = line.strip().split()\n",
    "        file_id = parts[1]\n",
    "        label_val = 1 if parts[-1] == \"bonafide\" else 0\n",
    "        file_labels[file_id] = label_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and label preparation\n",
    "spectrograms = []\n",
    "targets = []\n",
    "\n",
    "FIXED_FRAMES = 109\n",
    "\n",
    "for file_id, tag in file_labels.items():\n",
    "    path = os.path.join(AUDIO_DIR, file_id + \".flac\")\n",
    "    \n",
    "    signal, _ = librosa.load(path, sr=SRATE, duration=AUDIO_LEN)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=SRATE, n_mels=MEL_BANDS)\n",
    "    mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Pad or truncate for uniform input size\n",
    "    if mel_db.shape[1] < FIXED_FRAMES:\n",
    "        mel_db = np.pad(mel_db, ((0, 0), (0, FIXED_FRAMES - mel_db.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_db = mel_db[:, :FIXED_FRAMES]\n",
    "    \n",
    "    spectrograms.append(mel_db)\n",
    "    targets.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X_data = np.array(spectrograms)\n",
    "y_data = np.array(targets)\n",
    "\n",
    "# One-hot encode target classes\n",
    "y_encoded = utils.to_categorical(y_data, num_classes=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 training-validation split\n",
    "cutoff = int(0.8 * len(X_data))\n",
    "\n",
    "X_train, X_valid = X_data[:cutoff], X_data[cutoff:]\n",
    "y_train, y_valid = y_encoded[:cutoff], y_encoded[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture for Spectrogram Classification\n",
    "input_dim = (MEL_BANDS, X_train.shape[2], 1)\n",
    "inputs = layers.Input(shape=input_dim)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Conv2D(64, (3, 3), activation='relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(128, activation='relu')(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "outputs = layers.Dense(CLASSES, activation='softmax')(net)\n",
    "\n",
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_valid, y_valid))\n",
    "model.save(\"audio_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and prepare for evaluation\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "TEST_AUDIO_DIR = \"./TestEvaluation\"\n",
    "LOADED_MODEL_PATH = \"audio_cnn_model.h5\"\n",
    "\n",
    "model = load_model(LOADED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test set into mel spectrograms\n",
    "test_inputs = []\n",
    "\n",
    "test_audio_files = [f for f in os.listdir(TEST_AUDIO_DIR) if f.endswith(\".flac\")]\n",
    "\n",
    "for fname in test_audio_files:\n",
    "    fpath = os.path.join(TEST_AUDIO_DIR, fname)\n",
    "    audio, _ = librosa.load(fpath, sr=SRATE, duration=AUDIO_LEN)\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=SRATE, n_mels=MEL_BANDS)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    \n",
    "    if mel_db.shape[1] < FIXED_FRAMES:\n",
    "        mel_db = np.pad(mel_db, ((0, 0), (0, FIXED_FRAMES - mel_db.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_db = mel_db[:, :FIXED_FRAMES]\n",
    "\n",
    "    test_inputs.append(mel_db)\n",
    "\n",
    "X_test = np.array(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "test_probs = model.predict(X_test)\n",
    "\n",
    "# Get predicted class indices\n",
    "predicted_labels = np.argmax(test_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reference labels for evaluation\n",
    "label_protocol_path = \"test_eval.txt\"\n",
    "true_targets = {}\n",
    "\n",
    "with open(label_protocol_path, 'r') as f:\n",
    "    for entry in f:\n",
    "        parts = entry.strip().split()\n",
    "        if len(parts) >= 2:\n",
    "            true_targets[parts[0]] = parts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert textual labels to numeric format\n",
    "true_numeric = np.array([1 if lbl == \"bonafide\" else 0 for lbl in true_targets.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_list = [\"spoof\", \"bonafide\"]\n",
    "conf_mat = confusion_matrix(true_numeric, predicted_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=labels_list)\n",
    "disp.plot(cmap=\"Blues\", ax=ax)\n",
    "plt.title(\"Prediction Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "pos_probs = test_probs[:, 1]  # Probabilities for 'bonafide'\n",
    "\n",
    "fpr, tpr, _ = roc_curve(true_numeric, pos_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='navy')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(true_numeric, pos_probs)\n",
    "avg_prec = average_precision_score(true_numeric, pos_probs)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall, precision, label=f'AP = {avg_prec:.2f}', color='darkgreen')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(true_numeric, pos_probs, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Model Calibration', color='purple')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Ideal')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('True Fraction')\n",
    "plt.title('Calibration Plot')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=true_numeric, palette='pastel')\n",
    "plt.xticks([0, 1], [\"spoof\", \"bonafide\"])\n",
    "plt.title(\"True Label Distribution\")\n",
    "plt.ylabel(\"Samples\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "sample_files = [f for f in os.listdir(TEST_AUDIO_DIR) if f.endswith(\".flac\")][:5]\n",
    "\n",
    "for audio_file in sample_files:\n",
    "    audio_path = os.path.join(TEST_AUDIO_DIR, audio_file)\n",
    "    audio, _ = librosa.load(audio_path, sr=SRATE, duration=AUDIO_LEN)\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=SRATE, n_mels=MEL_BANDS)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_db, x_axis='time', y_axis='mel', sr=SRATE)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Mel Spectrogram - {audio_file}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "visual_model = tf.keras.models.load_model(\"audio_cnn_model.h5\")\n",
    "plot_model(visual_model, to_file='network_diagram.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
